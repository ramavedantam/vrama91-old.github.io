---
layout: home
title: Home
---

Hi! I am a second year Ph.D. student at the <a href='https://filebox.ece.vt.edu/~parikh/CVL.html'>Computer Vision Lab, Virginia Tech</a>. My advisor is <a href='http://filebox.ece.vt.edu/~parikh'>Devi Parikh</a>. I also work closely with <a href="http://www.larryzitnick.org">Larry Zitnick</a> from Facebook AI Research on various problems. I spend my time thinking about problems in Deep Learning/Machine Learning, Computer Vision (CV), and ultimately, Artifical Intelligence (AI).

I am interested in topics such as vision and language, unsupervised learning and common sense reasoning. A lot of my work focuses on leveraging abstract scenes made from clipart for high-level scene understanding, and language grounding.

I also care about issues of how we evaluate our models, as we edge towards higher-level AI-complete tasks. In my first project in grad school, I worked on a (now popularly used) evaluation metric for image captioning called <a href="http://vrama91.github.io/cider/">CIDEr</a>. 

I am always interested in how we can elicit more human-like behaviour from machine learning models. One concrete direction that really excites me is building language models to solve a task (say convincing a human) as opposed to necessarily being correct or accurate. The latter could in many cases be a strictly harder thing to do!

In a previous life, I was an undergrad in ECE at IIIT-Hyderabad where I worked with <a href='http://www.iiit.ac.in/people/faculty/mkrishna'>K. Madhava Krishna</a> in Robotics. <a href='https://sites.google.com/site/vrama91/'>Here</a> is a link to my old website.
<hr/>

<h3>News</h3>
<ul>
<li> I will be back at Google Research in Winter 2017, working with <a href="http://research.google.com/pubs/KevinMurphy.html">Kevin Murphy</a> on problems related to abstract scenes!
<li> Serving as reviewer for <a href="http://www.eccv2016.org/">ECCV 2016</a></li>
<li> I interned at Google Research in Summer 2016, with <a href="http://ai.stanford.edu/~gal/">Gal Chechik</a> and <a href="http://bengio.abracadoudou.com/">Samy Bengio</a>!
<li> Paper on <a href="https://arxiv.org/abs/1511.07067">Visual Word2Vec (vis-w2v): Learning Visually Grounded Word Embeddings using Abstract Scenes</a> accepted for publication in CVPR, 2016
<li> Paper on <a href="https://vision.ece.vt.edu/cs/">Learning Common Sense Through Visual Abstraction</a> accepted for publication in ICCV, 2015
<li> I interned at the <a href='http://cvn.ecp.fr/'>Center for Visual Computing</a> at INRIA in Summer, 2014 with <a href="http://cvn.ecp.fr/personnel/iasonas/">Iasonas Kokkinos</a></li>
<li> I attended the <a href='http://svg.dmi.unict.it/icvss2014/'>International Computer Vision Summer School</a> (ICVSS), 2014</li>
</ul>
<hr/>

<h3>Code</h3>
<ul>
<li> MSCOCO Caption Evaluation <a href="https://github.com/tylin/coco-caption"> code</a></li>
<li> <a href="https://github.com/vrama91/coco-caption">Codes</a> from MSCOCO Caption Evaluation for metrics (BLEU, ROUGE, CIDEr-D and METEOR), independent of the COCO annotations </li>
<li> Code for our CVPR'16 paper on <a href="https://github.com/satwikkottur/VisualWord2Vec">Learning Visually Grounded Word Embeddings</a>
</ul>	


<div align="center"><b>I have spent several months at</b></div>
<div align="center">
<table text-align="center", align="center"><tr><td>
	<a href='http://iiit.ac.in'><img src='public/images/iiit.png' width='100'></a></td> <td><a href='http://www.vt.edu'><img src='public/images/vt.png' width='100'></a></td><td><a href='http://www.siemens.com'><img src='public/images/siemens.png' width='100'></a></td><td><a href='http://www.inria.fr/en/centre/saclay'><img src='public/images/inria.png' width='100'></a></td><td><a href="https://research.google.com/"><img src="http://logok.org/wp-content/uploads/2015/09/Google-logo-2015-G-icon.png" width='100'></a></td></tr>
	<tr><td>2009-2013</td><td>2013-2015</td><td>Summer, 2012</td><td>Summer, 2014</td><td>Summer, 2016</td></tr>
</table>
</div>

<hr/>
If you like this layout/page, see <a href='demo-post'> this</a> to build your own using github+jekyll 
