---
layout: page
---

<h2>ArXiv Manuscripts</h2>
<ol>
<li> Xinlei Chen, Hao Fang, Tsung-Yi Lin, <em>Ramakrishna Vedantam</em>, Saurabh Gupta, Piotr Dollar, C. Lawrence Zitnick<br/>
	 <a href="http://arxiv.org/abs/1504.00325">Microsoft COCO Captions: Data Collection and Evaluation Server</a><br/>
	  [April, 2015]
	</li>
</ol>

<h2>Publications</h2>
<h3>2023</h3>
<ol>
<li>Karan Desai, Maximilian Nickel, Tanmay Rajpurohit, Justin Johnson, <em>Ramakrishna Vedantam</em><br/>
Hyperbolic Image-Text Representations. <br/>
In submission to International Conference on Machine Learning (ICML), 2023</li>
<li>Corentin Dancette, Spencer Whitehead, Rishabh Maheshwary, <em>Ramakrishna Vedantam</em>, Stefan Scherer, Xineli Chen, Matthieu Cord, Marcus Rohrbach<br/>
Improving Selective Visual Question Answering by Learning from Your Peers. [Coming Soon!] <br/>
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2023<br/></li>
<li>Daksh Idnani, Vivek Madan, Naman Goyal, David J. Schwab, <em>Ramakrishna Vedantam</em><br/>
<a href="https://openreview.net/forum?id=39z0zPZ0AvB">Dont forget the nullspace! Nullspace occupancy as a mechanism for out of distribution
failure.</a><br/>
International Conference on Learning Representations (ICLR), 2023 </li>
</ol>

<h3>2022</h3>
<ol>
<li>Sirui Xie, Ari S Morcos, Song-Chun Zhu, <em>Ramakrishna Vedantam</em><br/>
<a href="https://proceedings.mlr.press/v162/xie22b.html">COAT: Measuring Object Compositionality in Emergent Representations.</a><br/>
International Conference on Machine Learning (ICML), 2022</li>
</ol>

<h3>2021</h3>
<ol>
  <li><em>Ramakrishna Vedantam</em>, David Lopez-Paz<sup>*</sup>, David Schwab<sup>*</sup><br/>
	<a href="https://proceedings.neurips.cc/paper/2021/hash/ecf9902e0f61677c8de25ae60b654669-Abstract.html">An Empirical Investigation of Domain Generalization in Empirical Risk Minimizers</a><br/>
	Neural Information Processing Systems (NeurIPS), 2021 <br/>
	</li>
	<li><em>Ramakrishna Vedantam</em>, Arthur Szlam, Maximilian Nickel, Ari Morcos, Brenden Lake<br/>
	<a href="https://proceedings.mlr.press/v139/vedantam21a.html">CURI: A Benchmark for Productive Concept Learning Under Uncertainty</a><br/>
	International Conference on Machine Learning (ICML), 2021 <br/>
	<a href="http://github.com/facebookresearch/productive_concept_learning">[Code]</a><br/>
	</li>
</ol>

<h3>2020</h3>
<ol>
  <li>Yann Dubois, Douwe Keila, David J. Schwab, <em>Ramakrishna Vedantam</em><br/>
	<a href="https://arxiv.org/abs/2009.12789">Learning Optimal Representations with the Decodable Information Bottleneck</a><br/>
	Neural Information Processing Systems (NeurIPS), 2020 <b>(Spotlight)</b> <b> [Top 4%] </b><br/>
	</li>
  <li>Nirbhay Modhe, Prithvijit Chattopadhyay, Mohit Sharma, Abhishek Das, Devi Parikh, Dhruv Batra, <em>Ramakrishna Vedantam</em><br/>
	<a href="https://arxiv.org/abs/1907.10580">IR-VIC: IR-VIC: Unsupervised Discovery of Sub-goals for Transfer in RL</a><br/>
	International Joint Conference on Artificial Intelligence (IJCAI), 2020 <b> [Top 12.6%] </b><br/>
	</li>
</ol>

<h3>2019</h3>
<ol>
	<li><em>Ramakrishna Vedantam</em><br/>
	<a href="https://smartech.gatech.edu/handle/1853/60799">Interpretation, Grounding and Imagination for Machine Intelligence</a><br/>
	Ph.D. Thesis<br/>
	</li>
  <li><em> Ramakrishna Vedantam</em>, Karan Desai, Stefan Lee, Marcus Rohrbach, Dhruv Batra, Devi Parikh<br/>
	<a href="https://arxiv.org/abs/1902.07864">Probabilistic Neural-symbolic Models for Interpretable Visual Question Answering</a><br/>
	International Conference on Machine Learning (ICML), 2019 <b>(Long Oral)</b><b> [Top 4.2%]</b><br/>
	</li>
</ol>

<h3> 2018</h3>
<ol>
  <li> <em>Ramakrishna Vedantam</em>, Ian Fischer, Jonathan Huang, Kevin Murphy<br/>
	<a href="https://arxiv.org/abs/1705.10762">Generative Models of Visually Grounded Imagination</a><br/>
	International Conference on Learning Representations (ICLR), 2018 <b><a href="https://chillee.github.io/OpenReviewExplorer/index.html">[Top 10%]</a></b> <br/>
	<a href="https://github.com/google/joint_vae">[Code]</a><br/>
	</li>
</ol>

<h3>2017</h3>
<ol>
	<li> Ramprasaath R. Selvaraju, Michael Cogswell, Abhishek Das, <em>Ramakrishna Vedantam</em>, Devi Parikh, Dhruv Batra<br/>
	<a href="https://arxiv.org/abs/1610.02391">Grad-CAM: Why did you say that? Visual Explanations from Deep Networks via Gradient-based Localization</a><br/>
	International Conference on Computer Vision (ICCV), 2017 <br/>
	<a href="https://github.com/ramprs/grad-cam">[Code]</a><a href="https://ramprs.github.io/2017/01/21/Grad-CAM-Making-Off-the-Shelf-Deep-Models-Transparent-through-Visual-Explanations.html">[Blog]</a><a href="http://gradcam.cloudcv.org/">[Demo]</a>
	</li>
  <li> Ashwin K. Vijayakumar, <em>Ramakrishna Vedantam</em>, Devi Parikh<br/>
	<a href="https://arxiv.org/abs/1703.01720">Sound-Word2Vec: Learning Word Representations Grounded in Sounds</a><br/>
	Conference on Empirical Methods in Natural Language Processing (EMNLP), 2017 (Short)<br/>
	</li>
	<li> Prithvijit Chattopadhyay<sup>*</sup>, <em>Ramakrishna Vedantam<sup>*</sup></em>, Ramprasaath RS, Dhruv Batra, Devi Parikh<br/>
	<a href="http://arxiv.org/abs/1604.03505">Counting Everyday Objects in Everyday Scenes</a><br/>
	IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017 <b>(Spotlight)</b><b> [Top 8.2%]</b> <br/>
	<a href="https://github.com/prithv1/cvpr2017_counting">[Code]</a>
	</li>
  <li> <em>Ramakrishna Vedantam</em>, Samy Bengio, Kevin Murphy, Devi Parikh, Gal Chechik<br/>
	<a href="https://arxiv.org/abs/1701.02870">Context-aware Captions from Context-agnostic Supervision</a><br/>
	IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017 <b>(Spotlight)</b> <b> [Top 8.2%]</b><br/>
	<a href="https://filebox.ece.vt.edu/~vrama91/context_captions/">[Project Page]</a> <a href="https://arxiv.org/pdf/1701.02870">[arXiv]</a><br/>
	</li>
</ol>

<h3>2016</h3>
<ol>
	<li> Ramprasaath R. Selvaraju, Abhishek Das, <em>Ramakrishna Vedantam</em>, Michael Cogswell, Devi Parikh, Dhruv Batra<br/>
	<a href="https://arxiv.org/abs/1610.02391">Grad-CAM: Why did you say that? Visual Explanations from Deep Networks via Gradient-based Localization</a><br/>
	NIPS Workshop on Interpretable Machine Learning in Complex Systems, 2016 <br/>
	</li>
	<li> C. Lawrence Zitnick, <em>Ramakrishna Vedantam</em>, Devi Parikh<br/>
		<a href="https://filebox.ece.vt.edu/~parikh/Publications/ZitnickVedantamParikh_clipart_PAMI2015.pdf">Adopting Abstract Images for Semantic Scene Understanding</a> <br/>
		Special Issue on the best papers at the 2013 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)<br/>
		IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), 2016 
	</li>
	<li> 
	 Satwik Kottur<sup>*</sup>, <em>Ramakrishna Vedantam<sup>*</sup></em>, JoseÂ´ Moura, Devi Parikh <br/>
	 <a href="https://arxiv.org/pdf/1511.07067.pdf">Visual Word2Vec (vis-w2v): Learning Visually Grounded Word Embeddings Using Abstract Scenes</a><br/>
	  IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016 <br/>
		<a href="http://satwikkottur.github.io/VisualWord2Vec/">[Project Page]</a> <a href="https://github.com/satwikkottur/VisualWord2Vec">[Code]</a> <a href="https://arxiv.org/abs/1511.07067">[arXiv]</a>
	</li>
</ol>

<h3>2015</h3>
<ol>
	<li> <em> Ramakrishna Vedantam<sup>*</sup></em>, Xiao Lin<sup>*</sup>, Tanmay Batra, C. Lawrence Zitnick, Devi Parikh <br/>
		<a href="https://vision.ece.vt.edu/cs/rvxtld_cs_2015.pdf">Learning Common Sense Through Visual Abstraction</a> <br/>
		IEEE International Conference on Computer Vision (ICCV), 2015 <br/>
		<a href="https://vision.ece.vt.edu/cs">[Project page]</a> <a href="https://vision.ece.vt.edu/cs/#code_data">[Code]</a><br/>
	</li>
	<li> <em> Ramakrishna Vedantam</em>, C. Lawrence Zitnick, Devi Parikh <br/>
		<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Vedantam_CIDEr_Consensus-Based_Image_2015_CVPR_paper.pdf">CIDEr: Consensus-based Image Description Evaluation</a> <br/>
		IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015 <br/>
		<a href="http://vrama91.github.io/cider/">[Project Page]</a> <a href="https://github.com/vrama91/cider">[Code]</a><a href="http://arxiv.org/abs/1411.5726">[arXiv]</a><br/>
	</li>
</ol>
<sup>*</sup> Equal Contribution <br/>
